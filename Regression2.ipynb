{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "from lightgbm.sklearn import LGBMRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from pandas.io.json import json_normalize\n",
    "import json\n",
    "import gc\n",
    "gc.enable()\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "def load_df(csv_path='/home/baitong/pywork/RevenuePrediction/all/train.csv', nrows=None):\n",
    "    JSON_COLUMNS = ['device', 'geoNetwork', 'totals', 'trafficSource']\n",
    "    \n",
    "    df = pd.read_csv(csv_path, \n",
    "                     converters={column: json.loads for column in JSON_COLUMNS}, \n",
    "                     dtype={'fullVisitorId': 'str'}, # Important!!\n",
    "                     nrows=nrows)\n",
    "#     print(df.head())\n",
    "    for column in JSON_COLUMNS:\n",
    "        column_as_df = json_normalize(df[column])\n",
    "        column_as_df.columns = [f\"{column}.{subcolumn}\" for subcolumn in column_as_df.columns]\n",
    "        df = df.drop(column, axis=1).merge(column_as_df, right_index=True, left_index=True)\n",
    "    print(f\"Loaded {os.path.basename(csv_path)}. Shape: {df.shape}\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded train.csv. Shape: (903653, 55)\n",
      "Loaded test.csv. Shape: (804684, 53)\n",
      "CPU times: user 3min 51s, sys: 4.33 s, total: 3min 55s\n",
      "Wall time: 3min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "##读取数据\n",
    "train_df = load_df()\n",
    "test_df = load_df(\"/home/baitong/pywork/RevenuePrediction/all/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All functions\n",
    "\n",
    "#FUNCTION FOR PROVIDING FEATURE SUMMARY\n",
    "def feature_summary(df_fa):\n",
    "    print('DataFrame shape')\n",
    "    print('rows:',df_fa.shape[0])\n",
    "    print('cols:',df_fa.shape[1])\n",
    "    col_list=['Null','Unique_Count','Data_type','Max/Min','Mean','Std','Skewness','Sample_values']\n",
    "    df=pd.DataFrame(index=df_fa.columns,columns=col_list)\n",
    "    df['Null']=list([len(df_fa[col][df_fa[col].isnull()]) for i,col in enumerate(df_fa.columns)])\n",
    "    #df['%_Null']=list([len(df_fa[col][df_fa[col].isnull()])/df_fa.shape[0]*100 for i,col in enumerate(df_fa.columns)])\n",
    "    df['Unique_Count']=list([len(df_fa[col].unique()) for i,col in enumerate(df_fa.columns)])\n",
    "    df['Data_type']=list([df_fa[col].dtype for i,col in enumerate(df_fa.columns)])\n",
    "    for i,col in enumerate(df_fa.columns):\n",
    "        if 'float' in str(df_fa[col].dtype) or 'int' in str(df_fa[col].dtype):\n",
    "            df.at[col,'Max/Min']=str(round(df_fa[col].max(),2))+'/'+str(round(df_fa[col].min(),2))\n",
    "            df.at[col,'Mean']=df_fa[col].mean()\n",
    "            df.at[col,'Std']=df_fa[col].std()\n",
    "            df.at[col,'Skewness']=df_fa[col].skew()\n",
    "        df.at[col,'Sample_values']=list(df_fa[col].unique())\n",
    "           \n",
    "    return(df.fillna('-'))\n",
    "\n",
    "#FUNCTION FOR READING DICTIONARY ITEMS AND HANDLING KEYERROR\n",
    "def get_val(x,col):\n",
    "    try:\n",
    "        y=x[col]\n",
    "    except:\n",
    "        y=np.nan\n",
    "    return(y)\n",
    "\n",
    "#FUNCTION FOR CALCULATING RSME\n",
    "def rsme(y,pred):\n",
    "    return(mean_squared_error(y,pred)**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# feature_summary(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"totals.transactionRevenue\"] = train_df[\"totals.transactionRevenue\"].astype('float')\n",
    "#获取不变的常量列，模型无法在常量数据计学到东西，数据与处理时需要drop\n",
    "const_cols = [c for c in train_df.columns if train_df[c].nunique(dropna=False)==1 ]\n",
    "train_df = train_df.drop(const_cols , axis=1)\n",
    "test_df = test_df.drop(const_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop([\"trafficSource.campaignCode\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_summary(train_df)\n",
    "df_combi=pd.concat([train_df,test_df],ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_tmp = train_df\n",
    "df_combi.to_csv(\"/home/baitong/pywork/RevenuePrediction/all/df_combi.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['date'] = pd.to_datetime(train_df['visitStartTime'], unit='s')\n",
    "train_df['day_of_week'] = train_df['date'].dt.dayofweek\n",
    "train_df['hour'] = train_df['date'].dt.hour\n",
    "train_df['day'] = train_df['date'].dt.day\n",
    "train_df['month'] = train_df['date'].dt.month\n",
    "train_df['totals.transactionRevenue'].fillna(0, inplace=True)\n",
    "train_df['revenue_status']=train_df['totals.transactionRevenue'].apply(lambda x: 0 if x==0 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    892138\n",
       "1     11515\n",
       "Name: revenue_status, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['revenue_status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.head()\n",
    "#CONVERTING ALL THE STRINGS IN CATEGORICAL FEATURES TO LOWER CASE\n",
    "for col in train_df.columns:\n",
    "    if ((train_df[col].dtype=='object') & (col!='fullVisitorId')):\n",
    "        train_df[col]=train_df[col].apply(lambda x:str(x).lower())\n",
    "        \n",
    "#REPLACING STRING 'nan' WITH np.nan\n",
    "train_df.replace('nan',np.nan,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Newly created dummy cols: 29\n"
     ]
    }
   ],
   "source": [
    "#CONVERTING CATEGORICAL FEATURES (LESS THAN 10 UNIQUE VALUES) TO DUMMIES\n",
    "# train_df.drop(['device_isMobile'],axis=1,inplace=True)\n",
    "\n",
    "cat_col=['channelGrouping','device.deviceCategory','trafficSource.adwordsClickInfo.slot',\n",
    "         'trafficSource.adwordsClickInfo.adNetworkType',\n",
    "         'trafficSource.adwordsClickInfo.isVideoAd','trafficSource.medium',\n",
    "        'geoNetwork.continent']\n",
    "    \n",
    "dummy=pd.DataFrame()\n",
    "col_name = ['channelGrouping','deviceCategory','tsadwordsClickInfo_slot',\n",
    "                  'tsadwordsClickInfo_adNetworkType',\n",
    "                   'tsadwordsClickInfo_isVideoAd','tsmedium',\n",
    "            'geoNetwork_continent']\n",
    "for col,name in zip(cat_col,col_name):\n",
    "    dummy=pd.concat([dummy,pd.get_dummies(train_df[col],prefix=name)],axis=1)\n",
    "    \n",
    "print('Newly created dummy cols:',len(dummy.columns))\n",
    "train_df=pd.concat([train_df,dummy],axis=1)\n",
    "train_df.drop(cat_col,axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SOME BASIC DATA CLEANUP\n",
    "train_df['totals.newVisits'].fillna(0,inplace=True) \n",
    "train_df['totals.bounces'].fillna(0,inplace=True)\n",
    "train_df['trafficSource.adwordsClickInfo.page'].fillna(0,inplace=True)\n",
    "train_df['trafficSource.isTrueDirect'].replace({np.nan:0,'true':1},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop(['device.isMobile'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GENERATING RANKS FOR CATEGORICAL FEATURES WITH UNIQUE VALUES GREATER THAN 10\n",
    "#RANKS ARE GENERATED USING REVENUE PERCENTAGE\n",
    "cols=[x for x in train_df.columns if x not in ['fullVisitorId','sessionId','geoNetwork.networkDomain','trafficSource.adwordsClickInfo.gclId']]\n",
    "for col in cols:\n",
    "    if train_df[col].dtype=='object':\n",
    "        train_df[col].fillna('others',inplace=True)\n",
    "        col_list=['revenue_status','totals.transactionRevenue']\n",
    "        col_list.append(col)\n",
    "        print(col_list)\n",
    "        df=train_df[col_list].groupby(col).aggregate({col:['count'],'revenue_status':['sum'],'totals.transactionRevenue':['sum']}).reset_index()\n",
    "        \n",
    "        df.columns=[col,col+\"_count\",'revenue_status_sum','totals.transactionRevenue_sum']\n",
    "        df['revenue_perc']=df['totals.transactionRevenue_sum']/df[col+\"_count\"]\n",
    "        df['rank']=df['revenue_perc'].rank(ascending=1)\n",
    "#         print(df.head(1))\n",
    "        replace_dict={}\n",
    "        final_dict={}\n",
    "        #将每一个col列中的值按照rank排名 生成一个字典。即 {key=df[col].values：rank_value }  \n",
    "        for k,col_val in enumerate(df[col].values):\n",
    "            replace_dict[col_val]=df.iloc[k,5]\n",
    "        \n",
    "        final_dict[col]=replace_dict\n",
    "        #用排名替换原值\n",
    "        train_df.replace(final_dict,inplace=True)\n",
    "        del df,replace_dict,final_dict\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"/home/baitong/pywork/RevenuePrediction/get_dummie1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将字符串转换为数字\n",
    "train_df['geoNetwork.networkDomain'],unique=pd.factorize(train_df['geoNetwork.networkDomain'])\n",
    "train_df['trafficSource.adwordsClickInfo.gclId'],unique1=pd.factorize(train_df['trafficSource.adwordsClickInfo.gclId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"/home/baitong/pywork/RevenuePrediction/get_factotize1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=train_df.drop(['sessionId','visitId','date','geoNetwork.networkDomain','trafficSource.adwordsClickInfo.gclId'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 213 µs, sys: 2 µs, total: 215 µs\n",
      "Wall time: 220 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "agg_func={}\n",
    "agg_col=['fullVisitorId']\n",
    "for col in [x for x in X.columns if x not in ['fullVisitorId']]:\n",
    "    if col=='totals_transactionRevenue':\n",
    "        agg_func[col]=['sum']\n",
    "        agg_col.append(str(col)+'_sum')\n",
    "    elif col=='revenue_status':\n",
    "        agg_func[col]=['sum']\n",
    "        agg_col.append(str(col)+'_sum')\n",
    "    else:\n",
    "        agg_func[col]=['sum','max','min','mean','var','std']\n",
    "        agg_col.append(str(col)+'_sum')\n",
    "        agg_col.append(str(col)+'_max')\n",
    "        agg_col.append(str(col)+'_min')\n",
    "        agg_col.append(str(col)+'_mean')\n",
    "        agg_col.append(str(col)+'_var')\n",
    "        agg_col.append(str(col)+'_std')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.8 s, sys: 2.06 s, total: 20.9 s\n",
      "Wall time: 20.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X=X.groupby(X.fullVisitorId).aggregate(agg_func).reset_index()\n",
    "X.columns=agg_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.to_csv(\"/home/baitong/pywork/RevenuePrediction/X_agg.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.16 s, sys: 312 ms, total: 1.47 s\n",
      "Wall time: 1.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#CREATING y_dummy FOR USING STRATIFIED KFOLD\n",
    "y_dummy=X['revenue_status_sum'].apply(lambda x: 0 if x==0 else 1)\n",
    "\n",
    "#TARGET FEATURE CONVERTED TO NATURAL LOG\n",
    "# y=pd.Series(X['totals_transactionRevenue_sum'])\n",
    "y=X['totals.transactionRevenue_sum'].apply(lambda x: np.log1p(x))\n",
    "\n",
    "#PEPARING DATA FOR TRAINING LGBM MODEL\n",
    "X=X.drop(['totals.transactionRevenue_sum','fullVisitorId','revenue_status_sum'],axis=1)\n",
    "\n",
    "# #FINAL DATAFRAME FOR SUBMISSION\n",
    "# col=['fullVisitorId','totals.transactionRevenue_sum']\n",
    "# final=X_test[col] \n",
    "# final.columns=['fullVisitorId','PredictedLogRevenue']\n",
    "\n",
    "# #FINAL TEST FEATURES USED FOR PREDICTING SUBMISSION\n",
    "# X_test=X_test.drop(['fullVisitorId','totals_transactionRevenue_sum','revenue_status_sum'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting KFold iterations...\n",
      "Iteration: 1   rmse: 0.011243488312458461\n",
      "Iteration: 2   rmse: 0.011804135559095994\n",
      "Iteration: 3   rmse: 0.02023732194987488\n",
      "Iteration: 4   rmse: 0.011657404694332095\n",
      "Iteration: 5   rmse: 0.011608726923658247\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'score' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#LGBMRegressor. THIS REQUIRES FURTHER PARAMETER TUNINIG\n",
    "model=LGBMRegressor(boosting_type='gbdt',num_leaves=31,max_depth=-1,learning_rate=0.01,n_estimators=1000,max_bin=255,subsample_for_bin=50000,\n",
    "              objective=None,min_split_gain=0,min_child_weight=3,min_child_samples=10,subsample=1,subsample_freq=1,colsample_bytree=1,\n",
    "              reg_alpha=0.1,reg_lambda=0,seed=17,silent=False,nthread=-1,n_jobs=-1)\n",
    "\n",
    "\n",
    "k=1\n",
    "splits=5\n",
    "avg_score=0\n",
    "\n",
    "\n",
    "skf = StratifiedKFold(n_splits=splits, shuffle=True, random_state=200)\n",
    "print('\\nStarting KFold iterations...')\n",
    "for train_index,test_index in skf.split(X,y_dummy):\n",
    "    df_X=X.iloc[train_index,:]\n",
    "    df_y=y.iloc[train_index]\n",
    "    val_X=X.iloc[test_index,:]\n",
    "    val_y=y.iloc[test_index]\n",
    "\n",
    "    model.fit(df_X,df_y)\n",
    "\n",
    "    preds_x=pd.Series(model.predict(val_X))\n",
    "    acc=rsme(val_y,preds_x)\n",
    "    print('Iteration:',k,'  rmse:',acc)\n",
    "    \n",
    "#     if k==1:\n",
    "#         score=acc\n",
    "#         model1=model\n",
    "#         preds=pd.Series(model.predict(X_test))\n",
    "        \n",
    "#     else:\n",
    "#         preds1=pd.Series(model.predict(X_test))\n",
    "#         preds=preds+preds1\n",
    "#         if score>acc:\n",
    "#             score=acc\n",
    "#             model1=model\n",
    "    avg_score=avg_score+acc        \n",
    "    k=k+1\n",
    "# print('\\n Best score:',score,' Avg Score:',avg_score/splits)\n",
    "# preds=preds/splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
